# Backend API - Complete Implementation TODO

## ðŸš€ CRITICAL: Implementation Strategy

**BUILD EVERYTHING WITH REAL INTEGRATIONS FROM THE START**
- Connect to real Algorand LocalNet
- Use real IPFS daemon
- Implement full error handling
- Test every endpoint thoroughly
- Ensure perfect data format for frontend

## ðŸ“‹ Master Checklist

### Phase 1: Foundation Setup âœ…
- [ ] Set up Python FastAPI project structure
- [ ] Configure environment variables
- [ ] Install all dependencies
- [ ] Set up logging system
- [ ] Create health check endpoint
- [ ] Configure CORS for frontend

### Phase 2: Core Services
- [ ] Implement IPFS integration service
- [ ] Implement Algorand blockchain service
- [ ] Create database models (SQLite for caching)
- [ ] Set up service singleton pattern
- [ ] Add retry logic for external services
- [ ] Implement connection pooling

### Phase 3: API Endpoints
- [ ] Claims management endpoints
- [ ] Validation/voting endpoints
- [ ] Prediction market endpoints
- [ ] User reputation endpoints
- [ ] Statistics endpoints
- [ ] WebSocket for real-time updates

### Phase 4: Testing & Integration
- [ ] Unit tests for all services
- [ ] Integration tests for endpoints
- [ ] End-to-end flow testing
- [ ] Frontend integration testing
- [ ] Performance testing
- [ ] Error scenario testing

---

## ðŸ“ Project Structure

```
api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py                  # Configuration management
â”‚   â”œâ”€â”€ database.py                # Database setup
â”‚   â”œâ”€â”€ models/                    # Data models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ claim.py              # Claim models
â”‚   â”‚   â”œâ”€â”€ validation.py         # Validation models
â”‚   â”‚   â”œâ”€â”€ prediction.py         # Prediction market models
â”‚   â”‚   â””â”€â”€ user.py               # User/reputation models
â”‚   â”œâ”€â”€ schemas/                   # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ claim.py              # Request/response schemas
â”‚   â”‚   â”œâ”€â”€ validation.py
â”‚   â”‚   â”œâ”€â”€ prediction.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ services/                  # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ algorand.py           # Blockchain service
â”‚   â”‚   â”œâ”€â”€ ipfs.py               # IPFS service
â”‚   â”‚   â”œâ”€â”€ claim_service.py     # Claim business logic
â”‚   â”‚   â”œâ”€â”€ validation_service.py
â”‚   â”‚   â””â”€â”€ prediction_service.py
â”‚   â”œâ”€â”€ routers/                   # API endpoints
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ claims.py             # /claims endpoints
â”‚   â”‚   â”œâ”€â”€ validations.py       # /validations endpoints
â”‚   â”‚   â”œâ”€â”€ predictions.py       # /predictions endpoints
â”‚   â”‚   â”œâ”€â”€ users.py              # /users endpoints
â”‚   â”‚   â””â”€â”€ websocket.py         # WebSocket endpoint
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ errors.py             # Error handling
â”‚       â”œâ”€â”€ validators.py         # Input validation
â”‚       â””â”€â”€ cache.py              # Caching utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.py                  # Setup script
â”‚   â”œâ”€â”€ test_integration.py       # Integration test
â”‚   â””â”€â”€ deploy_contracts.py       # Contract deployment
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

---

## ðŸ”§ Phase 1: Foundation Setup

### Step 1.1: Install Dependencies

Create `requirements.txt`:
```txt
# Core
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0

# Algorand
py-algorand-sdk==2.5.0
algokit-utils==2.0.0

# IPFS
ipfshttpclient==0.8.0a2

# Database
sqlalchemy==2.0.23
sqlite3

# Data validation
pydantic==2.5.0
pydantic-settings==2.1.0

# Async support
aiohttp==3.9.1
asyncio==3.4.3

# Utils
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
httpx==0.25.2

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0

# Development
black==23.11.0
ruff==0.1.6

# Monitoring
prometheus-client==0.19.0

# WebSocket
websockets==12.0
```

Install command:
```bash
cd api
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Step 1.2: Environment Configuration

Create `.env`:
```env
# Algorand Configuration
ALGORAND_NODE_URL=http://localhost:4001
ALGORAND_INDEXER_URL=http://localhost:8980
ALGORAND_NETWORK=localnet

# Service Account (generated by algokit)
SERVICE_ACCOUNT_MNEMONIC="your 25 word mnemonic here"

# IPFS Configuration
IPFS_API_URL=http://localhost:5001
IPFS_GATEWAY_URL=http://localhost:8080

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true
API_WORKERS=1

# Database
DATABASE_URL=sqlite:///./defacto.db

# Security
SECRET_KEY=your-secret-key-here-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Frontend
FRONTEND_URL=http://localhost:3000

# ML Service (optional)
ML_SERVICE_URL=http://localhost:8001
ML_SERVICE_ENABLED=false

# Contract App IDs (will be populated after deployment)
CLAIM_REGISTRY_APP_ID=0
REPUTATION_TOKEN_APP_ID=0
VALIDATION_POOL_APP_ID=0
PREDICTION_MARKET_APP_ID=0
```

### Step 1.3: Configuration Module

Create `src/config.py`:
```python
from pydantic_settings import BaseSettings
from typing import Optional
import os
from pathlib import Path

class Settings(BaseSettings):
    # Algorand
    algorand_node_url: str = "http://localhost:4001"
    algorand_indexer_url: str = "http://localhost:8980"
    algorand_network: str = "localnet"
    service_account_mnemonic: str
    
    # IPFS
    ipfs_api_url: str = "http://localhost:5001"
    ipfs_gateway_url: str = "http://localhost:8080"
    
    # API
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    api_reload: bool = True
    
    # Database
    database_url: str = "sqlite:///./defacto.db"
    
    # Security
    secret_key: str
    access_token_expire_minutes: int = 30
    
    # Frontend
    frontend_url: str = "http://localhost:3000"
    
    # ML Service
    ml_service_url: str = "http://localhost:8001"
    ml_service_enabled: bool = False
    
    # Contracts
    claim_registry_app_id: int = 0
    reputation_token_app_id: int = 0
    validation_pool_app_id: int = 0
    prediction_market_app_id: int = 0
    
    # Validation Rules
    min_claim_title_length: int = 10
    max_claim_title_length: int = 200
    min_claim_content_length: int = 50
    max_claim_content_length: int = 5000
    min_stake_amount: int = 10
    max_stake_amount: int = 100
    voting_period_seconds: int = 86400  # 24 hours
    min_validators: int = 5
    initial_reputation: int = 100
    
    # Categories
    valid_categories: list = ["news", "science", "politics", "health", "technology"]
    valid_statuses: list = ["UNVERIFIED", "VERIFIED", "FALSE", "DISPUTED"]
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()

# Load contract IDs from deployment file if exists
def load_contract_ids():
    deployment_file = Path("../contracts/deployment_output.json")
    if deployment_file.exists():
        import json
        with open(deployment_file) as f:
            data = json.load(f)
            settings.claim_registry_app_id = data.get("claim_registry_app_id", 0)
            settings.reputation_token_app_id = data.get("reputation_token_app_id", 0)
            settings.validation_pool_app_id = data.get("validation_pool_app_id", 0)
            settings.prediction_market_app_id = data.get("prediction_market_app_id", 0)

load_contract_ids()
```

### Step 1.4: Main Application Setup

Create `src/main.py`:
```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
from contextlib import asynccontextmanager

from src.config import settings
from src.database import init_db
from src.routers import claims, validations, predictions, users, websocket
from src.services.algorand import AlgorandService
from src.services.ipfs import IPFSService

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize services
algorand_service = None
ipfs_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events"""
    # Startup
    logger.info("Starting DeFacto API...")
    
    # Initialize database
    init_db()
    
    # Initialize services
    global algorand_service, ipfs_service
    algorand_service = AlgorandService()
    ipfs_service = IPFSService()
    
    # Test connections
    try:
        await algorand_service.health_check()
        logger.info("âœ… Algorand connection successful")
    except Exception as e:
        logger.error(f"âŒ Algorand connection failed: {e}")
    
    try:
        await ipfs_service.health_check()
        logger.info("âœ… IPFS connection successful")
    except Exception as e:
        logger.error(f"âŒ IPFS connection failed: {e}")
    
    yield
    
    # Shutdown
    logger.info("Shutting down DeFacto API...")

# Create FastAPI app
app = FastAPI(
    title="DeFacto Protocol API",
    description="Decentralized fact-checking platform on Algorand",
    version="1.0.0",
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[settings.frontend_url],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Health check endpoint
@app.get("/health")
async def health_check():
    """Check API health and service status"""
    status = {
        "api": "healthy",
        "algorand": "unknown",
        "ipfs": "unknown",
        "database": "unknown"
    }
    
    try:
        await algorand_service.health_check()
        status["algorand"] = "healthy"
    except:
        status["algorand"] = "unhealthy"
    
    try:
        await ipfs_service.health_check()
        status["ipfs"] = "healthy"
    except:
        status["ipfs"] = "unhealthy"
    
    # Check database
    try:
        from src.database import SessionLocal
        db = SessionLocal()
        db.execute("SELECT 1")
        db.close()
        status["database"] = "healthy"
    except:
        status["database"] = "unhealthy"
    
    overall_health = all(v == "healthy" for v in status.values())
    return JSONResponse(
        status_code=200 if overall_health else 503,
        content=status
    )

# Include routers
app.include_router(claims.router, prefix="/claims", tags=["claims"])
app.include_router(validations.router, prefix="/validations", tags=["validations"])
app.include_router(predictions.router, prefix="/predictions", tags=["predictions"])
app.include_router(users.router, prefix="/users", tags=["users"])
app.include_router(websocket.router, prefix="/ws", tags=["websocket"])

# Global exception handler
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Unhandled exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )

if __name__ == "__main__":
    uvicorn.run(
        "src.main:app",
        host=settings.api_host,
        port=settings.api_port,
        reload=settings.api_reload
    )
```

---

## ðŸ”— Phase 2: Core Services Implementation

### Step 2.1: IPFS Service

Create `src/services/ipfs.py`:
```python
import ipfshttpclient
import json
import logging
from typing import Dict, Any, Optional
from src.config import settings

logger = logging.getLogger(__name__)

class IPFSService:
    def __init__(self):
        self.client = None
        self.connect()
    
    def connect(self):
        """Connect to IPFS daemon"""
        try:
            # Parse URL to get host and port
            url_parts = settings.ipfs_api_url.replace("http://", "").split(":")
            host = url_parts[0]
            port = int(url_parts[1]) if len(url_parts) > 1 else 5001
            
            self.client = ipfshttpclient.connect(
                addr=f"/ip4/{host}/tcp/{port}/http"
            )
            logger.info(f"Connected to IPFS at {settings.ipfs_api_url}")
        except Exception as e:
            logger.error(f"Failed to connect to IPFS: {e}")
            raise
    
    async def health_check(self) -> bool:
        """Check if IPFS is accessible"""
        try:
            self.client.version()
            return True
        except:
            return False
    
    async def upload_claim(self, claim_data: Dict[str, Any]) -> str:
        """
        Upload claim data to IPFS
        Returns: IPFS hash
        """
        try:
            # Convert to JSON
            json_data = json.dumps(claim_data, indent=2)
            
            # Upload to IPFS
            result = self.client.add_json(claim_data)
            ipfs_hash = result
            
            # Pin the content to prevent garbage collection
            self.client.pin.add(ipfs_hash)
            
            logger.info(f"Uploaded claim to IPFS: {ipfs_hash}")
            return ipfs_hash
            
        except Exception as e:
            logger.error(f"Failed to upload to IPFS: {e}")
            raise
    
    async def get_claim(self, ipfs_hash: str) -> Dict[str, Any]:
        """
        Retrieve claim data from IPFS
        """
        try:
            # Get content from IPFS
            data = self.client.get_json(ipfs_hash)
            logger.info(f"Retrieved claim from IPFS: {ipfs_hash}")
            return data
            
        except Exception as e:
            logger.error(f"Failed to retrieve from IPFS: {e}")
            raise
    
    async def upload_file(self, file_content: bytes, filename: str) -> str:
        """
        Upload a file to IPFS (for evidence, images, etc.)
        """
        try:
            result = self.client.add(file_content)
            ipfs_hash = result['Hash']
            
            # Pin the file
            self.client.pin.add(ipfs_hash)
            
            logger.info(f"Uploaded file {filename} to IPFS: {ipfs_hash}")
            return ipfs_hash
            
        except Exception as e:
            logger.error(f"Failed to upload file to IPFS: {e}")
            raise
```

### Step 2.2: Algorand Blockchain Service

Create `src/services/algorand.py`:
```python
from algosdk import account, mnemonic
from algosdk.v2client import algod, indexer
from algosdk.transaction import ApplicationCallTxn, StateSchema, Transaction
from algosdk.atomic_transaction_composer import AtomicTransactionComposer, TransactionWithSigner
from algosdk.abi import Method, Contract
from algosdk.logic import get_application_address
import base64
import json
import logging
from typing import Dict, Any, Optional, List
from src.config import settings

logger = logging.getLogger(__name__)

class AlgorandService:
    def __init__(self):
        # Initialize Algorand clients
        self.algod_client = algod.AlgodClient(
            algod_token="",
            algod_address=settings.algorand_node_url
        )
        
        self.indexer_client = indexer.IndexerClient(
            indexer_token="",
            indexer_address=settings.algorand_indexer_url
        )
        
        # Load service account
        self.service_account = self._load_service_account()
        
        # Contract app IDs
        self.claim_registry_id = settings.claim_registry_app_id
        self.reputation_token_id = settings.reputation_token_app_id
        self.validation_pool_id = settings.validation_pool_app_id
        self.prediction_market_id = settings.prediction_market_app_id
    
    def _load_service_account(self) -> Dict[str, str]:
        """Load service account from mnemonic"""
        try:
            private_key = mnemonic.to_private_key(settings.service_account_mnemonic)
            address = account.address_from_private_key(private_key)
            
            return {
                "address": address,
                "private_key": private_key
            }
        except Exception as e:
            logger.error(f"Failed to load service account: {e}")
            raise
    
    async def health_check(self) -> bool:
        """Check if Algorand node is accessible"""
        try:
            status = self.algod_client.status()
            return status.get("last-round", 0) > 0
        except:
            return False
    
    async def submit_claim_to_blockchain(
        self, 
        ipfs_hash: str, 
        category: str
    ) -> Dict[str, Any]:
        """
        Submit a claim to the blockchain
        Returns: claim_id and transaction_id
        """
        try:
            # Get suggested parameters
            params = self.algod_client.suggested_params()
            
            # Create application call transaction
            txn = ApplicationCallTxn(
                sender=self.service_account["address"],
                sp=params,
                index=self.claim_registry_id,
                app_args=[
                    b"submit_claim",
                    ipfs_hash.encode(),
                    category.encode()
                ],
                on_complete=0  # NoOp
            )
            
            # Sign transaction
            signed_txn = txn.sign(self.service_account["private_key"])
            
            # Send transaction
            tx_id = self.algod_client.send_transaction(signed_txn)
            
            # Wait for confirmation
            result = self._wait_for_confirmation(tx_id)
            
            # Extract claim ID from logs
            claim_id = self._extract_claim_id(result)
            
            logger.info(f"Submitted claim to blockchain: ID={claim_id}, TX={tx_id}")
            
            return {
                "claim_id": claim_id,
                "tx_id": tx_id
            }
            
        except Exception as e:
            logger.error(f"Failed to submit claim to blockchain: {e}")
            raise
    
    async def get_claim_from_blockchain(self, claim_id: int) -> Dict[str, Any]:
        """
        Retrieve claim data from blockchain
        """
        try:
            # Create box name
            box_name = f"claim_{claim_id}".encode()
            
            # Get box value
            result = self.algod_client.application_box_by_name(
                self.claim_registry_id,
                box_name
            )
            
            # Parse box value
            value = base64.b64decode(result["value"]).decode()
            parts = value.split("|")
            
            return {
                "ipfs_hash": parts[0],
                "category": parts[1],
                "status": parts[2] if len(parts) > 2 else "UNVERIFIED"
            }
            
        except Exception as e:
            logger.error(f"Failed to get claim from blockchain: {e}")
            raise
    
    async def submit_vote(
        self,
        claim_id: int,
        vote: bool,
        stake_amount: int,
        voter_address: Optional[str] = None
    ) -> str:
        """
        Submit a vote for a claim
        """
        try:
            # Use service account if no voter specified
            sender = voter_address or self.service_account["address"]
            
            params = self.algod_client.suggested_params()
            
            # Create vote transaction
            txn = ApplicationCallTxn(
                sender=sender,
                sp=params,
                index=self.validation_pool_id,
                app_args=[
                    b"cast_vote",
                    claim_id.to_bytes(8, 'big'),
                    (1 if vote else 0).to_bytes(1, 'big'),
                    stake_amount.to_bytes(8, 'big')
                ],
                foreign_apps=[self.reputation_token_id],
                on_complete=0
            )
            
            # Sign with service account (in production, user would sign)
            signed_txn = txn.sign(self.service_account["private_key"])
            
            # Send transaction
            tx_id = self.algod_client.send_transaction(signed_txn)
            
            # Wait for confirmation
            self._wait_for_confirmation(tx_id)
            
            logger.info(f"Submitted vote: claim={claim_id}, vote={vote}, stake={stake_amount}")
            
            return tx_id
            
        except Exception as e:
            logger.error(f"Failed to submit vote: {e}")
            raise
    
    async def get_user_balance(self, user_address: str) -> int:
        """
        Get user's reputation token balance
        """
        try:
            # Create box name for user reputation
            box_name = f"rep_{user_address}".encode()
            
            # Get box value
            result = self.algod_client.application_box_by_name(
                self.reputation_token_id,
                box_name
            )
            
            # Parse balance
            balance = int.from_bytes(base64.b64decode(result["value"]), 'big')
            
            return balance
            
        except Exception as e:
            # User might not be opted in yet
            logger.info(f"User {user_address} not found, returning 0 balance")
            return 0
    
    async def opt_in_user(self, user_address: Optional[str] = None) -> Dict[str, Any]:
        """
        Opt in user to reputation system
        """
        try:
            sender = user_address or self.service_account["address"]
            params = self.algod_client.suggested_params()
            
            txn = ApplicationCallTxn(
                sender=sender,
                sp=params,
                index=self.reputation_token_id,
                app_args=[b"opt_in"],
                on_complete=0
            )
            
            signed_txn = txn.sign(self.service_account["private_key"])
            tx_id = self.algod_client.send_transaction(signed_txn)
            self._wait_for_confirmation(tx_id)
            
            return {
                "status": "opted_in",
                "tx_id": tx_id,
                "initial_balance": settings.initial_reputation
            }
            
        except Exception as e:
            logger.error(f"Failed to opt in user: {e}")
            raise
    
    def _wait_for_confirmation(self, tx_id: str, timeout: int = 10):
        """Wait for transaction confirmation"""
        last_round = self.algod_client.status()["last-round"]
        
        while timeout > 0:
            try:
                pending_txn = self.algod_client.pending_transaction_info(tx_id)
                if pending_txn.get("confirmed-round", 0) > 0:
                    return pending_txn
                if pending_txn.get("pool-error"):
                    raise Exception(f"Transaction rejected: {pending_txn['pool-error']}")
            except Exception as e:
                if "not found" not in str(e):
                    raise
            
            last_round += 1
            self.algod_client.status_after_block(last_round)
            timeout -= 1
        
        raise Exception(f"Transaction {tx_id} not confirmed after timeout")
    
    def _extract_claim_id(self, txn_result: Dict) -> int:
        """Extract claim ID from transaction logs"""
        try:
            # Parse logs to find claim ID
            if "logs" in txn_result:
                for log in txn_result["logs"]:
                    # Decode log (it's base64 encoded)
                    decoded = base64.b64decode(log).decode('utf-8')
                    if decoded.startswith("claim_id:"):
                        return int(decoded.split(":")[1])
            
            # Fallback: calculate from global state
            app_info = self.algod_client.application_info(self.claim_registry_id)
            global_state = app_info["params"]["global-state"]
            for item in global_state:
                key = base64.b64decode(item["key"]).decode()
                if key == "claim_counter":
                    return item["value"]["uint"]
            
            return 1  # Default to 1 if not found
            
        except Exception as e:
            logger.error(f"Failed to extract claim ID: {e}")
            return 1
```

### Step 2.3: Database Models

Create `src/database.py`:
```python
from sqlalchemy import create_engine, Column, Integer, String, DateTime, Boolean, Float, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime
from src.config import settings

# Create engine
engine = create_engine(
    settings.database_url,
    connect_args={"check_same_thread": False} if "sqlite" in settings.database_url else {}
)

# Create session
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for models
Base = declarative_base()

def init_db():
    """Initialize database tables"""
    Base.metadata.create_all(bind=engine)

def get_db():
    """Dependency for getting database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

Create `src/models/claim.py`:
```python
from sqlalchemy import Column, Integer, String, DateTime, Text, Float
from src.database import Base
from datetime import datetime

class Claim(Base):
    __tablename__ = "claims"
    
    id = Column(Integer, primary_key=True, index=True)
    claim_id = Column(Integer, unique=True, index=True)  # Blockchain ID
    title = Column(String(200), nullable=False)
    content = Column(Text, nullable=False)
    category = Column(String(50), nullable=False, index=True)
    status = Column(String(20), default="UNVERIFIED", index=True)
    ipfs_hash = Column(String(100), unique=True, nullable=False)
    tx_id = Column(String(100))
    
    # Vote counts (cached from blockchain)
    yes_votes = Column(Integer, default=0)
    no_votes = Column(Integer, default=0)
    total_stake = Column(Integer, default=0)
    
    # Metadata
    submitted_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    voting_ends_at = Column(DateTime)
    
    # ML analysis (optional)
    propaganda_score = Column(Float)
    risk_level = Column(String(20))
```

---

## ðŸ“¡ Phase 3: API Endpoints Implementation

### Step 3.1: Claim Endpoints

Create `src/schemas/claim.py`:
```python
from pydantic import BaseModel, Field, validator
from typing import Optional, List
from datetime import datetime
from src.config import settings

class ClaimSubmissionRequest(BaseModel):
    title: str = Field(..., min_length=10, max_length=200)
    content: str = Field(..., min_length=50, max_length=5000)
    category: str
    evidence_urls: Optional[List[str]] = Field(default_factory=list, max_items=10)
    
    @validator('category')
    def validate_category(cls, v):
        if v not in settings.valid_categories:
            raise ValueError(f'Category must be one of {settings.valid_categories}')
        return v
    
    @validator('evidence_urls')
    def validate_urls(cls, v):
        if v:
            for url in v:
                if not url.startswith(('http://', 'https://')):
                    raise ValueError(f'Invalid URL: {url}')
        return v

class ClaimSubmissionResponse(BaseModel):
    claim_id: int
    ipfs_hash: str
    tx_id: str
    status: str = "UNVERIFIED"
    submitted_at: datetime

class ClaimDetailResponse(BaseModel):
    claim_id: int
    title: str
    content: str
    category: str
    status: str
    ipfs_hash: str
    evidence_urls: List[str]
    yes_votes: int
    no_votes: int
    submitted_at: datetime
    voting_ends_at: Optional[datetime]
    propaganda_score: Optional[float]

class ClaimListItem(BaseModel):
    claim_id: int
    title: str
    category: str
    status: str
    submitted_at: datetime
    preview: Optional[str]
    vote_count: Optional[int]

class ClaimsListResponse(BaseModel):
    claims: List[ClaimListItem]
    total: int
    has_more: bool
```

Create `src/routers/claims.py`:
```python
from fastapi import APIRouter, HTTPException, Depends, Query
from typing import Optional, List
from datetime import datetime, timedelta
from sqlalchemy.orm import Session

from src.database import get_db
from src.models.claim import Claim
from src.schemas.claim import (
    ClaimSubmissionRequest,
    ClaimSubmissionResponse,
    ClaimDetailResponse,
    ClaimsListResponse,
    ClaimListItem
)
from src.services.algorand import AlgorandService
from src.services.ipfs import IPFSService
from src.config import settings
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

# Initialize services
algorand_service = AlgorandService()
ipfs_service = IPFSService()

@router.post("/submit", response_model=ClaimSubmissionResponse)
async def submit_claim(
    claim: ClaimSubmissionRequest,
    db: Session = Depends(get_db)
):
    """Submit a new claim"""
    try:
        # Prepare claim data for IPFS
        claim_data = {
            "title": claim.title,
            "content": claim.content,
            "category": claim.category,
            "evidence_urls": claim.evidence_urls or [],
            "submitted_at": datetime.utcnow().isoformat(),
            "submitter": "anonymous"  # In production, use actual user ID
        }
        
        # Upload to IPFS
        ipfs_hash = await ipfs_service.upload_claim(claim_data)
        
        # Submit to blockchain
        blockchain_result = await algorand_service.submit_claim_to_blockchain(
            ipfs_hash=ipfs_hash,
            category=claim.category
        )
        
        # Save to database for fast queries
        db_claim = Claim(
            claim_id=blockchain_result["claim_id"],
            title=claim.title,
            content=claim.content,
            category=claim.category,
            status="UNVERIFIED",
            ipfs_hash=ipfs_hash,
            tx_id=blockchain_result["tx_id"],
            voting_ends_at=datetime.utcnow() + timedelta(seconds=settings.voting_period_seconds)
        )
        
        db.add(db_claim)
        db.commit()
        db.refresh(db_claim)
        
        return ClaimSubmissionResponse(
            claim_id=db_claim.claim_id,
            ipfs_hash=ipfs_hash,
            tx_id=blockchain_result["tx_id"],
            status="UNVERIFIED",
            submitted_at=db_claim.submitted_at
        )
        
    except Exception as e:
        logger.error(f"Failed to submit claim: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/{claim_id}", response_model=ClaimDetailResponse)
async def get_claim(
    claim_id: int,
    db: Session = Depends(get_db)
):
    """Get a specific claim by ID"""
    try:
        # Try database first (faster)
        db_claim = db.query(Claim).filter(Claim.claim_id == claim_id).first()
        
        if not db_claim:
            # Try blockchain if not in database
            blockchain_data = await algorand_service.get_claim_from_blockchain(claim_id)
            ipfs_data = await ipfs_service.get_claim(blockchain_data["ipfs_hash"])
            
            return ClaimDetailResponse(
                claim_id=claim_id,
                title=ipfs_data["title"],
                content=ipfs_data["content"],
                category=blockchain_data["category"],
                status=blockchain_data["status"],
                ipfs_hash=blockchain_data["ipfs_hash"],
                evidence_urls=ipfs_data.get("evidence_urls", []),
                yes_votes=0,
                no_votes=0,
                submitted_at=datetime.fromisoformat(ipfs_data["submitted_at"])
            )
        
        return ClaimDetailResponse(
            claim_id=db_claim.claim_id,
            title=db_claim.title,
            content=db_claim.content,
            category=db_claim.category,
            status=db_claim.status,
            ipfs_hash=db_claim.ipfs_hash,
            evidence_urls=[],  # Load from IPFS if needed
            yes_votes=db_claim.yes_votes,
            no_votes=db_claim.no_votes,
            submitted_at=db_claim.submitted_at,
            voting_ends_at=db_claim.voting_ends_at,
            propaganda_score=db_claim.propaganda_score
        )
        
    except Exception as e:
        logger.error(f"Failed to get claim {claim_id}: {e}")
        raise HTTPException(status_code=404, detail="Claim not found")

@router.get("/", response_model=ClaimsListResponse)
async def list_claims(
    limit: int = Query(10, ge=1, le=100),
    offset: int = Query(0, ge=0),
    category: Optional[str] = None,
    status: Optional[str] = None,
    sort: str = Query("newest", regex="^(newest|oldest|most_votes)$"),
    db: Session = Depends(get_db)
):
    """List claims with pagination and filters"""
    try:
        query = db.query(Claim)
        
        # Apply filters
        if category:
            query = query.filter(Claim.category == category)
        if status:
            query = query.filter(Claim.status == status)
        
        # Apply sorting
        if sort == "newest":
            query = query.order_by(Claim.submitted_at.desc())
        elif sort == "oldest":
            query = query.order_by(Claim.submitted_at.asc())
        elif sort == "most_votes":
            query = query.order_by((Claim.yes_votes + Claim.no_votes).desc())
        
        # Get total count
        total = query.count()
        
        # Apply pagination
        claims = query.offset(offset).limit(limit).all()
        
        # Format response
        claim_items = [
            ClaimListItem(
                claim_id=c.claim_id,
                title=c.title,
                category=c.category,
                status=c.status,
                submitted_at=c.submitted_at,
                preview=c.content[:200] + "..." if len(c.content) > 200 else c.content,
                vote_count=c.yes_votes + c.no_votes
            )
            for c in claims
        ]
        
        return ClaimsListResponse(
            claims=claim_items,
            total=total,
            has_more=(offset + limit) < total
        )
        
    except Exception as e:
        logger.error(f"Failed to list claims: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### Step 3.2: Validation Endpoints

Create `src/schemas/validation.py`:
```python
from pydantic import BaseModel, Field
from typing import Optional, Dict
from datetime import datetime

class VoteSubmissionRequest(BaseModel):
    claim_id: int
    vote: bool  # true = valid, false = invalid
    stake_amount: int = Field(..., ge=10, le=100)

class VoteSubmissionResponse(BaseModel):
    status: str = "vote_submitted"
    tx_id: str
    new_balance: Optional[int] = None

class PendingValidation(BaseModel):
    claim_id: int
    title: str
    category: str
    time_remaining: int  # seconds
    current_votes: Dict[str, int]
    user_can_vote: bool = True

class PendingValidationsResponse(BaseModel):
    validations: list[PendingValidation]
    user_balance: Optional[int] = None
```

Create `src/routers/validations.py`:
```python
from fastapi import APIRouter, HTTPException, Depends
from typing import List
from datetime import datetime
from sqlalchemy.orm import Session

from src.database import get_db
from src.models.claim import Claim
from src.schemas.validation import (
    VoteSubmissionRequest,
    VoteSubmissionResponse,
    PendingValidation,
    PendingValidationsResponse
)
from src.services.algorand import AlgorandService
from src.config import settings
import logging

logger = logging.getLogger(__name__)

router = APIRouter()
algorand_service = AlgorandService()

@router.post("/vote", response_model=VoteSubmissionResponse)
async def submit_vote(
    vote_request: VoteSubmissionRequest,
    db: Session = Depends(get_db)
):
    """Submit a vote for a claim"""
    try:
        # Check if claim exists and voting is open
        claim = db.query(Claim).filter(Claim.claim_id == vote_request.claim_id).first()
        if not claim:
            raise HTTPException(status_code=404, detail="Claim not found")
        
        if claim.voting_ends_at and datetime.utcnow() > claim.voting_ends_at:
            raise HTTPException(status_code=400, detail="Voting period closed")
        
        # Submit vote to blockchain
        tx_id = await algorand_service.submit_vote(
            claim_id=vote_request.claim_id,
            vote=vote_request.vote,
            stake_amount=vote_request.stake_amount
        )
        
        # Update vote counts in database (cache)
        if vote_request.vote:
            claim.yes_votes += 1
            claim.total_stake += vote_request.stake_amount
        else:
            claim.no_votes += 1
            claim.total_stake += vote_request.stake_amount
        
        db.commit()
        
        return VoteSubmissionResponse(
            status="vote_submitted",
            tx_id=tx_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to submit vote: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/pending", response_model=PendingValidationsResponse)
async def get_pending_validations(
    db: Session = Depends(get_db)
):
    """Get claims pending validation"""
    try:
        # Get claims where voting is still open
        now = datetime.utcnow()
        pending_claims = db.query(Claim).filter(
            Claim.status == "UNVERIFIED",
            Claim.voting_ends_at > now
        ).all()
        
        validations = []
        for claim in pending_claims:
            time_remaining = int((claim.voting_ends_at - now).total_seconds())
            
            validations.append(PendingValidation(
                claim_id=claim.claim_id,
                title=claim.title,
                category=claim.category,
                time_remaining=time_remaining,
                current_votes={
                    "yes": claim.yes_votes,
                    "no": claim.no_votes,
                    "total_stake": claim.total_stake
                },
                user_can_vote=True  # In production, check if user already voted
            ))
        
        return PendingValidationsResponse(
            validations=validations,
            user_balance=settings.initial_reputation  # In production, get actual balance
        )
        
    except Exception as e:
        logger.error(f"Failed to get pending validations: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### Step 3.3: Prediction Market Endpoints

Create `src/schemas/prediction.py`:
```python
from pydantic import BaseModel, Field
from typing import Optional, Dict, List
from datetime import datetime

class PredictionMarket(BaseModel):
    market_id: int
    claim_id: int
    title: str
    description: str
    total_yes_stake: float
    total_no_stake: float
    yes_price: float  # Price to buy YES position (0-1)
    no_price: float   # Price to buy NO position (0-1)
    expires_at: datetime
    resolved: bool = False
    outcome: Optional[bool] = None

class CreateMarketRequest(BaseModel):
    claim_id: int
    initial_liquidity: float = Field(..., ge=100, le=10000)
    duration_hours: int = Field(24, ge=1, le=168)  # 1 hour to 1 week

class CreateMarketResponse(BaseModel):
    market_id: int
    tx_id: str
    yes_price: float
    no_price: float

class PlaceBetRequest(BaseModel):
    market_id: int
    position: str = Field(..., regex="^(YES|NO)$")
    amount: float = Field(..., ge=10, le=1000)

class PlaceBetResponse(BaseModel):
    tx_id: str
    shares_bought: float
    avg_price: float
    potential_payout: float

class MarketPosition(BaseModel):
    market_id: int
    position: str  # YES or NO
    shares: float
    avg_buy_price: float
    current_value: float
    potential_payout: float

class UserPositionsResponse(BaseModel):
    positions: List[MarketPosition]
    total_invested: float
    total_current_value: float
```

Create `src/routers/predictions.py`:
```python
from fastapi import APIRouter, HTTPException, Depends, Query
from typing import List, Optional
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
import math

from src.database import get_db
from src.schemas.prediction import (
    PredictionMarket,
    CreateMarketRequest,
    CreateMarketResponse,
    PlaceBetRequest,
    PlaceBetResponse,
    MarketPosition,
    UserPositionsResponse
)
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

# In-memory storage for MVP (use database in production)
markets = {}
positions = {}
market_counter = 0

def calculate_price(yes_stake: float, no_stake: float) -> tuple[float, float]:
    """
    Calculate market prices using constant product AMM (like Uniswap)
    Price = stake_side / total_stake
    """
    total = yes_stake + no_stake
    if total == 0:
        return 0.5, 0.5
    
    yes_price = yes_stake / total
    no_price = no_stake / total
    
    # Ensure prices sum to 1 and are between 0.01 and 0.99
    yes_price = max(0.01, min(0.99, yes_price))
    no_price = max(0.01, min(0.99, no_price))
    
    return yes_price, no_price

@router.post("/create-market", response_model=CreateMarketResponse)
async def create_prediction_market(
    request: CreateMarketRequest,
    db: Session = Depends(get_db)
):
    """Create a new prediction market for a claim"""
    try:
        global market_counter
        
        # Check if claim exists
        from src.models.claim import Claim
        claim = db.query(Claim).filter(Claim.claim_id == request.claim_id).first()
        if not claim:
            raise HTTPException(status_code=404, detail="Claim not found")
        
        # Check if market already exists for this claim
        existing = next((m for m in markets.values() if m["claim_id"] == request.claim_id), None)
        if existing:
            raise HTTPException(status_code=400, detail="Market already exists for this claim")
        
        # Create market
        market_counter += 1
        market_id = market_counter
        
        # Initialize with equal liquidity
        initial_yes = request.initial_liquidity / 2
        initial_no = request.initial_liquidity / 2
        
        yes_price, no_price = calculate_price(initial_yes, initial_no)
        
        market = {
            "market_id": market_id,
            "claim_id": request.claim_id,
            "title": f"Will '{claim.title}' be verified as TRUE?",
            "description": f"Prediction market for claim #{request.claim_id}",
            "total_yes_stake": initial_yes,
            "total_no_stake": initial_no,
            "yes_price": yes_price,
            "no_price": no_price,
            "created_at": datetime.utcnow(),
            "expires_at": datetime.utcnow() + timedelta(hours=request.duration_hours),
            "resolved": False,
            "outcome": None,
            "liquidity_provider": "system",
            "total_volume": 0
        }
        
        markets[market_id] = market
        
        return CreateMarketResponse(
            market_id=market_id,
            tx_id=f"market_tx_{market_id}",
            yes_price=yes_price,
            no_price=no_price
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to create market: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/bet", response_model=PlaceBetResponse)
async def place_bet(
    request: PlaceBetRequest
):
    """Place a bet on a prediction market"""
    try:
        # Check if market exists
        market = markets.get(request.market_id)
        if not market:
            raise HTTPException(status_code=404, detail="Market not found")
        
        # Check if market is still open
        if datetime.utcnow() > market["expires_at"]:
            raise HTTPException(status_code=400, detail="Market has expired")
        
        if market["resolved"]:
            raise HTTPException(status_code=400, detail="Market already resolved")
        
        # Calculate shares bought using AMM formula
        if request.position == "YES":
            current_stake = market["total_yes_stake"]
            opposite_stake = market["total_no_stake"]
            
            # Calculate shares using constant product formula
            # New shares = sqrt(k * (amount + current)) - current
            k = current_stake * opposite_stake  # Constant product
            new_stake = current_stake + request.amount
            new_opposite = k / new_stake
            shares_bought = opposite_stake - new_opposite
            
            # Update market
            market["total_yes_stake"] = new_stake
            market["total_no_stake"] = new_opposite
            
        else:  # NO position
            current_stake = market["total_no_stake"]
            opposite_stake = market["total_yes_stake"]
            
            k = current_stake * opposite_stake
            new_stake = current_stake + request.amount
            new_opposite = k / new_stake
            shares_bought = opposite_stake - new_opposite
            
            # Update market
            market["total_no_stake"] = new_stake
            market["total_yes_stake"] = new_opposite
        
        # Recalculate prices
        market["yes_price"], market["no_price"] = calculate_price(
            market["total_yes_stake"],
            market["total_no_stake"]
        )
        
        # Update volume
        market["total_volume"] += request.amount
        
        # Store position (in production, use database)
        user_id = "user_123"  # In production, get from auth
        position_key = f"{user_id}_{request.market_id}_{request.position}"
        
        if position_key in positions:
            # Update existing position
            pos = positions[position_key]
            total_amount = pos["amount"] + request.amount
            total_shares = pos["shares"] + shares_bought
            pos["avg_price"] = total_amount / total_shares if total_shares > 0 else 0
            pos["amount"] = total_amount
            pos["shares"] = total_shares
        else:
            # Create new position
            positions[position_key] = {
                "user_id": user_id,
                "market_id": request.market_id,
                "position": request.position,
                "amount": request.amount,
                "shares": shares_bought,
                "avg_price": request.amount / shares_bought if shares_bought > 0 else 0,
                "created_at": datetime.utcnow()
            }
        
        # Calculate potential payout
        potential_payout = shares_bought * 1.0  # Pays $1 per share if correct
        
        return PlaceBetResponse(
            tx_id=f"bet_tx_{request.market_id}_{datetime.utcnow().timestamp()}",
            shares_bought=round(shares_bought, 4),
            avg_price=round(request.amount / shares_bought if shares_bought > 0 else 0, 4),
            potential_payout=round(potential_payout, 2)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to place bet: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/markets", response_model=List[PredictionMarket])
async def list_markets(
    status: Optional[str] = Query(None, regex="^(open|closed|resolved)$"),
    claim_id: Optional[int] = None
):
    """List all prediction markets"""
    try:
        result = []
        now = datetime.utcnow()
        
        for market in markets.values():
            # Apply filters
            if claim_id and market["claim_id"] != claim_id:
                continue
            
            if status == "open" and (market["resolved"] or now > market["expires_at"]):
                continue
            elif status == "closed" and (market["resolved"] or now <= market["expires_at"]):
                continue
            elif status == "resolved" and not market["resolved"]:
                continue
            
            result.append(PredictionMarket(
                market_id=market["market_id"],
                claim_id=market["claim_id"],
                title=market["title"],
                description=market["description"],
                total_yes_stake=market["total_yes_stake"],
                total_no_stake=market["total_no_stake"],
                yes_price=market["yes_price"],
                no_price=market["no_price"],
                expires_at=market["expires_at"],
                resolved=market["resolved"],
                outcome=market["outcome"]
            ))
        
        return result
        
    except Exception as e:
        logger.error(f"Failed to list markets: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/markets/{market_id}", response_model=PredictionMarket)
async def get_market(market_id: int):
    """Get details of a specific market"""
    market = markets.get(market_id)
    if not market:
        raise HTTPException(status_code=404, detail="Market not found")
    
    return PredictionMarket(
        market_id=market["market_id"],
        claim_id=market["claim_id"],
        title=market["title"],
        description=market["description"],
        total_yes_stake=market["total_yes_stake"],
        total_no_stake=market["total_no_stake"],
        yes_price=market["yes_price"],
        no_price=market["no_price"],
        expires_at=market["expires_at"],
        resolved=market["resolved"],
        outcome=market["outcome"]
    )

@router.get("/my-positions", response_model=UserPositionsResponse)
async def get_user_positions():
    """Get current user's positions across all markets"""
    try:
        user_id = "user_123"  # In production, get from auth
        user_positions = []
        total_invested = 0
        total_current_value = 0
        
        for key, pos in positions.items():
            if not key.startswith(user_id):
                continue
            
            market = markets.get(pos["market_id"])
            if not market:
                continue
            
            # Calculate current value
            if pos["position"] == "YES":
                current_price = market["yes_price"]
            else:
                current_price = market["no_price"]
            
            current_value = pos["shares"] * current_price
            potential_payout = pos["shares"] * 1.0  # Pays $1 per share if correct
            
            user_positions.append(MarketPosition(
                market_id=pos["market_id"],
                position=pos["position"],
                shares=pos["shares"],
                avg_buy_price=pos["avg_price"],
                current_value=current_value,
                potential_payout=potential_payout
            ))
            
            total_invested += pos["amount"]
            total_current_value += current_value
        
        return UserPositionsResponse(
            positions=user_positions,
            total_invested=round(total_invested, 2),
            total_current_value=round(total_current_value, 2)
        )
        
    except Exception as e:
        logger.error(f"Failed to get user positions: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/markets/{market_id}/resolve")
async def resolve_market(
    market_id: int,
    outcome: bool,
    db: Session = Depends(get_db)
):
    """Resolve a prediction market (admin only)"""
    try:
        market = markets.get(market_id)
        if not market:
            raise HTTPException(status_code=404, detail="Market not found")
        
        if market["resolved"]:
            raise HTTPException(status_code=400, detail="Market already resolved")
        
        # Get claim status to determine outcome
        from src.models.claim import Claim
        claim = db.query(Claim).filter(Claim.claim_id == market["claim_id"]).first()
        
        if claim and claim.status in ["VERIFIED", "FALSE"]:
            outcome = claim.status == "VERIFIED"
        
        market["resolved"] = True
        market["outcome"] = outcome
        
        # In production, distribute winnings to correct positions
        logger.info(f"Market {market_id} resolved with outcome: {outcome}")
        
        return {"status": "resolved", "outcome": outcome}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to resolve market: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### Step 3.4: User/Reputation Endpoints

Create `src/routers/users.py`:
```python
from fastapi import APIRouter, HTTPException, Depends
from typing import Optional
from src.services.algorand import AlgorandService
from src.config import settings
import logging

logger = logging.getLogger(__name__)

router = APIRouter()
algorand_service = AlgorandService()

@router.post("/opt-in")
async def opt_in_user(
    address: Optional[str] = None
):
    """Opt in user to reputation system"""
    try:
        result = await algorand_service.opt_in_user(address)
        return result
    except Exception as e:
        logger.error(f"Failed to opt in user: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/balance/{address}")
async def get_user_balance(address: str):
    """Get user's reputation token balance"""
    try:
        balance = await algorand_service.get_user_balance(address)
        return {"address": address, "balance": balance}
    except Exception as e:
        logger.error(f"Failed to get balance: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### Step 3.5: WebSocket for Real-time Updates

Create `src/routers/websocket.py`:
```python
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from typing import Set
import json
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

class ConnectionManager:
    def __init__(self):
        self.active_connections: Set[WebSocket] = set()
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.add(websocket)
        logger.info(f"Client connected. Total connections: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        self.active_connections.discard(websocket)
        logger.info(f"Client disconnected. Total connections: {len(self.active_connections)}")
    
    async def broadcast(self, message: dict):
        """Send message to all connected clients"""
        disconnected = set()
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except:
                disconnected.add(connection)
        
        # Clean up disconnected clients
        for conn in disconnected:
            self.disconnect(conn)

manager = ConnectionManager()

@router.websocket("/")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            # Keep connection alive
            data = await websocket.receive_text()
            
            # Handle ping/pong
            if data == "ping":
                await websocket.send_text("pong")
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# Helper function to broadcast events
async def broadcast_event(event_type: str, payload: dict):
    await manager.broadcast({
        "type": event_type,
        "payload": payload
    })
```

---

## ðŸ§ª Phase 4: Testing Implementation

### Step 4.1: Unit Tests

Create `tests/unit/test_services.py`:
```python
import pytest
from unittest.mock import Mock, patch
from src.services.algorand import AlgorandService
from src.services.ipfs import IPFSService

@pytest.mark.asyncio
async def test_ipfs_upload():
    """Test IPFS upload functionality"""
    with patch('ipfshttpclient.connect') as mock_connect:
        mock_client = Mock()
        mock_client.add_json.return_value = "QmTest123"
        mock_connect.return_value = mock_client
        
        service = IPFSService()
        result = await service.upload_claim({"title": "Test"})
        
        assert result == "QmTest123"
        mock_client.add_json.assert_called_once()

@pytest.mark.asyncio
async def test_algorand_health_check():
    """Test Algorand health check"""
    with patch('algosdk.v2client.algod.AlgodClient') as mock_algod:
        mock_client = Mock()
        mock_client.status.return_value = {"last-round": 100}
        mock_algod.return_value = mock_client
        
        service = AlgorandService()
        result = await service.health_check()
        
        assert result == True
```

### Step 4.2: Integration Tests

Create `tests/integration/test_api.py`:
```python
import pytest
from fastapi.testclient import TestClient
from src.main import app

client = TestClient(app)

def test_health_endpoint():
    """Test health check endpoint"""
    response = client.get("/health")
    assert response.status_code in [200, 503]
    assert "api" in response.json()

def test_submit_claim():
    """Test claim submission"""
    claim_data = {
        "title": "Test Claim Title",
        "content": "This is a test claim with at least 50 characters to meet the minimum requirement.",
        "category": "technology",
        "evidence_urls": []
    }
    
    response = client.post("/claims/submit", json=claim_data)
    
    # Will fail without running services, but structure is correct
    if response.status_code == 200:
        data = response.json()
        assert "claim_id" in data
        assert "ipfs_hash" in data
        assert "tx_id" in data

def test_list_claims():
    """Test listing claims"""
    response = client.get("/claims?limit=10&offset=0")
    
    if response.status_code == 200:
        data = response.json()
        assert "claims" in data
        assert "total" in data
        assert "has_more" in data
```

### Step 4.3: End-to-End Test Script

Create `scripts/test_integration.py`:
```python
#!/usr/bin/env python3
"""
End-to-end integration test for DeFacto backend
"""

import requests
import json
import time
import sys
from datetime import datetime

API_URL = "http://localhost:8000"

def test_health():
    """Test API health"""
    print("Testing API health...")
    try:
        response = requests.get(f"{API_URL}/health")
        status = response.json()
        print(f"âœ… API Status: {status}")
        return response.status_code == 200
    except Exception as e:
        print(f"âŒ Health check failed: {e}")
        return False

def test_submit_claim():
    """Test claim submission flow"""
    print("\nTesting claim submission...")
    
    claim_data = {
        "title": f"Integration Test Claim {datetime.now().isoformat()}",
        "content": "This is an automated integration test claim to verify the entire backend pipeline is working correctly.",
        "category": "technology",
        "evidence_urls": ["https://example.com/evidence"]
    }
    
    try:
        response = requests.post(f"{API_URL}/claims/submit", json=claim_data)
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Claim submitted: ID={result['claim_id']}, IPFS={result['ipfs_hash']}")
            return result['claim_id']
        else:
            print(f"âŒ Failed to submit claim: {response.text}")
            return None
    except Exception as e:
        print(f"âŒ Error submitting claim: {e}")
        return None

def test_get_claim(claim_id):
    """Test retrieving a claim"""
    print(f"\nTesting claim retrieval for ID {claim_id}...")
    
    try:
        response = requests.get(f"{API_URL}/claims/{claim_id}")
        if response.status_code == 200:
            claim = response.json()
            print(f"âœ… Retrieved claim: {claim['title']}")
            return True
        else:
            print(f"âŒ Failed to retrieve claim: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Error retrieving claim: {e}")
        return False

def test_list_claims():
    """Test listing claims"""
    print("\nTesting claims list...")
    
    try:
        response = requests.get(f"{API_URL}/claims?limit=5")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Listed {len(data['claims'])} claims (total: {data['total']})")
            return True
        else:
            print(f"âŒ Failed to list claims: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Error listing claims: {e}")
        return False

def test_pending_validations():
    """Test pending validations endpoint"""
    print("\nTesting pending validations...")
    
    try:
        response = requests.get(f"{API_URL}/validations/pending")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Found {len(data['validations'])} pending validations")
            return True
        else:
            print(f"âŒ Failed to get pending validations: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Error getting validations: {e}")
        return False

def test_prediction_markets():
    """Test prediction market endpoints"""
    print("\nTesting prediction markets...")
    
    try:
        # List markets
        response = requests.get(f"{API_URL}/predictions/markets")
        if response.status_code == 200:
            markets = response.json()
            print(f"âœ… Listed {len(markets)} prediction markets")
            return True
        else:
            print(f"âŒ Failed to list markets: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Error with prediction markets: {e}")
        return False

def main():
    print("=" * 50)
    print("DeFacto Backend Integration Test")
    print("=" * 50)
    
    tests_passed = 0
    tests_failed = 0
    
    # Run tests
    if test_health():
        tests_passed += 1
    else:
        tests_failed += 1
    
    claim_id = test_submit_claim()
    if claim_id:
        tests_passed += 1
        
        if test_get_claim(claim_id):
            tests_passed += 1
        else:
            tests_failed += 1
    else:
        tests_failed += 1
    
    if test_list_claims():
        tests_passed += 1
    else:
        tests_failed += 1
    
    if test_pending_validations():
        tests_passed += 1
    else:
        tests_failed += 1
    
    if test_prediction_markets():
        tests_passed += 1
    else:
        tests_failed += 1
    
    # Summary
    print("\n" + "=" * 50)
    print("Test Summary:")
    print(f"âœ… Passed: {tests_passed}")
    print(f"âŒ Failed: {tests_failed}")
    print("=" * 50)
    
    if tests_failed == 0:
        print("\nðŸŽ‰ All tests passed! Backend is ready for frontend integration.")
        sys.exit(0)
    else:
        print(f"\nâš ï¸  {tests_failed} test(s) failed. Please fix issues before proceeding.")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ðŸš€ Deployment & Running Instructions

### Step 1: Setup Script

Create `scripts/setup.py`:
```python
#!/usr/bin/env python3
"""
Setup script for DeFacto backend
"""

import os
import sys
import subprocess
import json
from pathlib import Path

def run_command(cmd, description):
    """Run a shell command"""
    print(f"\n{description}...")
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âŒ Failed: {result.stderr}")
        return False
    print(f"âœ… Success")
    return True

def check_prerequisites():
    """Check if all prerequisites are installed"""
    print("Checking prerequisites...")
    
    # Check Python
    if not run_command("python --version", "Checking Python"):
        print("Please install Python 3.10+")
        return False
    
    # Check Docker
    if not run_command("docker --version", "Checking Docker"):
        print("Please install Docker Desktop")
        return False
    
    # Check AlgoKit
    if not run_command("algokit --version", "Checking AlgoKit"):
        print("Please install AlgoKit: https://github.com/algorandfoundation/algokit-cli")
        return False
    
    return True

def setup_environment():
    """Set up environment file"""
    print("\nSetting up environment...")
    
    env_file = Path(".env")
    if not env_file.exists():
        print("Creating .env file from template...")
        subprocess.run("cp .env.example .env", shell=True)
        print("âš ï¸  Please edit .env file with your configuration")
        return False
    
    print("âœ… Environment file exists")
    return True

def start_services():
    """Start required services"""
    print("\nStarting services...")
    
    # Start LocalNet
    if not run_command("algokit localnet start", "Starting Algorand LocalNet"):
        return False
    
    # Start IPFS
    print("Starting IPFS daemon...")
    subprocess.Popen(["ipfs", "daemon"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print("âœ… IPFS daemon started")
    
    return True

def install_dependencies():
    """Install Python dependencies"""
    print("\nInstalling dependencies...")
    
    if not run_command("pip install -r requirements.txt", "Installing Python packages"):
        return False
    
    return True

def main():
    print("=" * 50)
    print("DeFacto Backend Setup")
    print("=" * 50)
    
    os.chdir(Path(__file__).parent.parent)  # Change to api directory
    
    if not check_prerequisites():
        print("\nâŒ Prerequisites check failed")
        sys.exit(1)
    
    if not setup_environment():
        print("\nâš ï¸  Please configure .env file and run setup again")
        sys.exit(1)
    
    if not install_dependencies():
        print("\nâŒ Failed to install dependencies")
        sys.exit(1)
    
    if not start_services():
        print("\nâŒ Failed to start services")
        sys.exit(1)
    
    print("\n" + "=" * 50)
    print("âœ… Setup complete!")
    print("\nTo start the API server, run:")
    print("  python src/main.py")
    print("\nOr for development with auto-reload:")
    print("  uvicorn src.main:app --reload")
    print("=" * 50)

if __name__ == "__main__":
    main()
```

### Step 2: Run Instructions

Create `api/README.md`:
```markdown
# DeFacto Backend API

## Quick Start

1. **Setup Environment**
   ```bash
   cd api
   python scripts/setup.py
   ```

2. **Configure Environment**
   Edit `.env` file with your settings

3. **Start Services**
   ```bash
   # Terminal 1: Start Algorand LocalNet
   algokit localnet start
   
   # Terminal 2: Start IPFS
   ipfs daemon
   
   # Terminal 3: Deploy contracts (if not done)
   cd ../contracts
   python deploy.py
   cd ../api
   ```

4. **Run API Server**
   ```bash
   python src/main.py
   ```
   
   Or with auto-reload for development:
   ```bash
   uvicorn src.main:app --reload
   ```

5. **Test Integration**
   ```bash
   python scripts/test_integration.py
   ```

## API Documentation

Once running, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest tests/unit/test_services.py
```

## Common Issues

### "Cannot connect to Algorand"
```bash
algokit localnet stop
algokit localnet start
```

### "IPFS not responding"
```bash
ipfs shutdown
ipfs daemon
```

### "Port 8000 already in use"
```bash
lsof -i :8000
kill -9 [PID]
```

## Production Deployment

1. Update `.env` with production values
2. Use proper database (PostgreSQL)
3. Enable HTTPS
4. Set up monitoring
5. Configure rate limiting
6. Add authentication middleware
```

---

## âœ… Final Checklist

### Before Frontend Integration

- [ ] All services start without errors
- [ ] Health check returns all services healthy
- [ ] Can submit a claim successfully
- [ ] Can retrieve submitted claim
- [ ] Can list claims with pagination
- [ ] Can submit votes
- [ ] Can get pending validations
- [ ] Prediction markets work
- [ ] WebSocket connects successfully
- [ ] All integration tests pass

### Performance Requirements

- [ ] API responds in < 500ms for reads
- [ ] API responds in < 2s for writes
- [ ] Can handle 100 concurrent users
- [ ] Database queries are optimized
- [ ] Caching is implemented where appropriate

### Security Requirements

- [ ] Input validation on all endpoints
- [ ] SQL injection prevention
- [ ] XSS prevention
- [ ] CORS properly configured
- [ ] Rate limiting implemented
- [ ] Secrets in environment variables
- [ ] Error messages don't leak sensitive info

---

## ðŸŽ‰ Success Criteria

The backend is complete when:

1. **All endpoints work** as documented
2. **Frontend can integrate** without changes
3. **Data formats match** exactly as specified
4. **Error handling** is comprehensive
5. **Tests pass** consistently
6. **Performance** meets requirements
7. **Security** best practices followed
8. **Documentation** is complete

Once all criteria are met, the backend is ready for production!